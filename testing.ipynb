{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "from typing import List, Dict, Any, Optional\n",
    "import jinja2\n",
    "import json\n",
    "from abc import ABC, abstractmethod\n",
    "from tavily import TavilyClient\n",
    "import os\n",
    "\n",
    "\n",
    "# Objective: Create a conversation object that can be used to send messages to the model and get responses and tools\n",
    "class Conversation:\n",
    "    def __init__(self, model: str = \"gemini/gemini-2.0-flash\"):\n",
    "        self.model = model\n",
    "        self.messages = []\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        self.messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    def get_response(self, tool_choice: str = \"auto\", tools: Optional[List] = None):\n",
    "        if tools is None:\n",
    "            tool_choice = None\n",
    "        return completion(\n",
    "            model=self.model,\n",
    "            messages=self.messages,\n",
    "            tools=tools,\n",
    "            tool_choice=tool_choice,\n",
    "        )\n",
    "\n",
    "\n",
    "# Updated abstract Tool class that enforces `name` and `terminating` and accepts extra kwargs.\n",
    "class Tool(ABC):\n",
    "    def __init__(self, name: str, terminating: bool = False):\n",
    "        self.name = name\n",
    "        self.terminating = terminating\n",
    "\n",
    "    @abstractmethod\n",
    "    def run(self, conversation: Conversation, **kwargs) -> str:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_config(self) -> Dict[str, Any]:\n",
    "        pass\n",
    "\n",
    "\n",
    "# Reasoning tool (non‐terminating)\n",
    "class Reasoning(Tool):\n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"reasoning\", terminating=False)\n",
    "\n",
    "    def run(self, conversation: Conversation, **kwargs) -> str:\n",
    "        with open(\"templates/reasoning.jinja2\", \"r\") as file:\n",
    "            reasoning_template = jinja2.Template(file.read()).render()\n",
    "        conversation.add_message(\"system\", reasoning_template)\n",
    "        response = conversation.get_response()\n",
    "        conversation.messages.pop()  # remove the reasoning message\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def get_config(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": self.name,\n",
    "                \"description\": \"This tool provides reasoning for the given context.\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "\n",
    "# Respond tool (terminating) – note the extra parameter `response_type`\n",
    "class Respond(Tool):\n",
    "    def __init__(self, response_types: List[str]):\n",
    "        # Mark this tool as terminating since its response is meant to be final.\n",
    "        super().__init__(name=\"respond\", terminating=True)\n",
    "        self.response_types = response_types\n",
    "\n",
    "    def run(self, conversation: Conversation, response_type: str, **kwargs) -> str:\n",
    "        with open(f\"templates/{response_type}.jinja2\", \"r\") as file:\n",
    "            template_content = jinja2.Template(file.read()).render()\n",
    "        conversation.add_message(\"system\", template_content)\n",
    "        response = conversation.get_response()\n",
    "        conversation.messages.pop()\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def get_config(self) -> dict:\n",
    "        return {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": self.name,\n",
    "                \"description\": \"This tool provides responses for the given user message.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"response_type\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The type of response to be generated.\",\n",
    "                            \"enum\": self.response_types,\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"response_type\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "\n",
    "\n",
    "# Search tool (non‐terminating)\n",
    "class Search(Tool):\n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"search\", terminating=False)\n",
    "        self.tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "\n",
    "    def run(self, conversation: Conversation, query: str, **kwargs) -> str:\n",
    "        response = self.tavily_client.search(query)\n",
    "        return response\n",
    "\n",
    "    def get_config(self) -> dict:\n",
    "        return {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": self.name,\n",
    "                \"description\": \"This tool provides search results for the given query.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The query to search for.\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"query\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "\n",
    "\n",
    "# An agent is a tool that can be used to interact with the model and get responses and use tools as required.\n",
    "class Agent(Tool):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        description: str,\n",
    "        max_turns: int = 3,\n",
    "        tools: List[Tool] = [],\n",
    "        terminating_tools: List[Tool] = None,\n",
    "        forced_terminating_tool: Tool = None,\n",
    "    ):\n",
    "        self._name = name\n",
    "        self.description = description\n",
    "        self.max_turns = max_turns\n",
    "        self.available_tools = {tool.name: tool for tool in tools}\n",
    "        self.terminating_tools = terminating_tools\n",
    "        self.forced_terminating_tool = forced_terminating_tool\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return self._name\n",
    "\n",
    "    def run(self, conversation: Conversation) -> str:\n",
    "        for turn in range(self.max_turns):\n",
    "            tool, function_args = self.get_next_action(conversation)\n",
    "            print(f\"Using the {tool.name} tool with arguments {function_args}\")\n",
    "            response = tool.run(conversation, **function_args)\n",
    "            if tool.name == self.terminating_tool.name:\n",
    "                return response\n",
    "\n",
    "            conversation.add_message(\n",
    "                \"user\",\n",
    "                f\"The {tool.name} tool has been used and it responded with {response}\",\n",
    "            )\n",
    "        return self.terminating_tool.run(self.conversation)\n",
    "\n",
    "    def get_next_action(self, conversation: Conversation) -> Tool:\n",
    "        response = conversation.get_response(\n",
    "            tool_choice=\"required\",\n",
    "            tools=[tool.get_config() for tool in self.available_tools.values()],\n",
    "        )\n",
    "        tool_calls = response.choices[0].message.tool_calls\n",
    "        function_name = tool_calls[0].function.name\n",
    "        function_args = json.loads(tool_calls[0].function.arguments)\n",
    "        return self.available_tools[function_name], function_args\n",
    "\n",
    "    def get_config(self) -> dict:\n",
    "        return {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": self.name,\n",
    "                \"description\": self.description,\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"templates/system_message.jinja2\", \"r\") as file:\n",
    "    system_message = jinja2.Template(file.read()).render(tools=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the research_agent tool with arguments {}\n",
      "Using the search tool with arguments {'query': 'climate litigation'}\n",
      "Using the reasoning tool with arguments {}\n",
      "Using the respond tool with arguments {'response_type': 'write_report'}\n",
      "Using the respond tool with arguments {'response_type': 'clarification'}\n",
      "Okay, I see that you're interested in researching climate litigation. Based on your initial query and the search results, it seems like you want to understand:\n",
      "\n",
      "*   **What climate litigation is:** The definition, types, and trends of climate change litigation.\n",
      "*   **Key players:** Who is involved in these cases (plaintiffs and defendants).\n",
      "*   **Goals of climate litigation:** What these cases aim to achieve (policy changes, compensation, etc.).\n",
      "*   **Impact and challenges:** The successes, limitations, and overall impact of climate litigation.\n",
      "\n",
      "Is that a correct assessment of what you're hoping to achieve with this research? Are there any specific aspects of climate litigation that you're particularly interested in (e.g., a specific region, type of case, or legal theory)?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "conversation = Conversation()\n",
    "conversation.add_message(\"system\", system_message)\n",
    "\n",
    "respond = Respond(response_types=[\"respond\", \"clarification\"])\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Autonomous market research agent\",\n",
    "    description=\"This agent is designed to help users with market research.\",\n",
    "    tools=[\n",
    "        Reasoning(),\n",
    "        respond,\n",
    "        research_agent\n",
    "    ],\n",
    "    terminating_tool=respond,\n",
    ")\n",
    "\n",
    "conversation.add_message(\"user\", \"I want to research climate litigation\")\n",
    "\n",
    "\n",
    "response = agent.run(conversation)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autonomous-market-research-agent-8W59owSb-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
